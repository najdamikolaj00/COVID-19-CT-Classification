{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from PIL import Image\n",
    "from sklearn.metrics import classification_report as report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "train_transformer = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomResizedCrop((224), scale=(0.5, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "val_transformer = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_COVID='CT_COVID.txt'\n",
    "txt_NonCOVID='CT_NonCOVID.txt'\n",
    "\n",
    "data_COVID='Data/CT_COVID'\n",
    "data_NonCOVID='Data/CT_NonCOVID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_COVID = r'C:\\Users\\PC\\ML_Classification_Project\\COVID-19-CT-Classification\\Data\\CT_COVID'\n",
    "data_NonCOVID = r'C:\\Users\\PC\\ML_Classification_Project\\COVID-19-CT-Classification\\Data\\CT_NonCOVID'\n",
    "\n",
    "with open(txt_COVID, 'r') as file:\n",
    "    COVID_train_paths = [os.path.join(data_COVID, line) for line in file.read().splitlines()]\n",
    "\n",
    "with open(txt_NonCOVID, 'r') as file:\n",
    "    NonCOVID_train_paths = [os.path.join(data_NonCOVID, line) for line in file.read().splitlines()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "COVID_train_labels = np.ones(len(COVID_train_paths))\n",
    "NonCOVID_train_labels = np.zeros(len(NonCOVID_train_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_image_paths = np.concatenate((COVID_train_paths, NonCOVID_train_paths), axis=0)\n",
    "all_labels = np.concatenate((COVID_train_labels, NonCOVID_train_labels), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cv_dataset_split(all_image_paths, all_labels, k_folds):\n",
    "    random_state = 42\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True, random_state=random_state)\n",
    "\n",
    "    train_splits = []\n",
    "    val_splits = []\n",
    "\n",
    "    for train_index, val_index in kfold.split(all_image_paths):\n",
    "        train_paths_fold = all_image_paths[train_index]\n",
    "        val_paths_fold = all_image_paths[val_index]\n",
    "        train_labels_fold = all_labels[train_index]\n",
    "        val_labels_fold = all_labels[val_index]\n",
    "\n",
    "        train_splits.append((train_paths_fold, train_labels_fold))\n",
    "        val_splits.append((val_paths_fold, val_labels_fold))\n",
    "\n",
    "    return train_splits, val_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fold(train_paths, train_labels, val_paths, val_labels):\n",
    "    # Load the images and labels for training set with transformations\n",
    "    train_images = []\n",
    "    for path in train_paths:\n",
    "        image = Image.open(path).convert(\"RGB\")\n",
    "        image = train_transformer(image)  # Apply transformations\n",
    "        train_images.append(image)\n",
    "\n",
    "    # Resize images to a consistent size\n",
    "    resized_train_images = [transforms.Resize((224, 224))(image) for image in train_images]\n",
    "\n",
    "    # Convert the list of resized images to a NumPy array\n",
    "    X_train = np.array([np.array(image) for image in resized_train_images])\n",
    "    X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "    y_train = train_labels\n",
    "\n",
    "    # Load the images and labels for validation set with transformations\n",
    "    val_images = []\n",
    "    for path in val_paths:\n",
    "        image = Image.open(path).convert(\"RGB\")\n",
    "        image = val_transformer(image)  # Apply transformations\n",
    "        val_images.append(image)\n",
    "\n",
    "    # Resize images to a consistent size\n",
    "    resized_val_images = [transforms.Resize((224, 224))(image) for image in val_images]\n",
    "\n",
    "    # Convert the list of resized images to a NumPy array\n",
    "    X_val = np.array([np.array(image) for image in resized_val_images])\n",
    "    X_val = X_val.reshape(X_val.shape[0], -1)\n",
    "    y_val = val_labels\n",
    "\n",
    "    # Step 2: Perform PCA Dimensionality Reduction\n",
    "    # Apply PCA to reduce the dimensionality of the image data\n",
    "    pca = PCA(n_components=173)  # Choose the desired number of components\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_val_pca = pca.transform(X_val)\n",
    "\n",
    "    # Step 3: Train the SVM Classifier\n",
    "    # Initialize an SVM classifier\n",
    "    svm_classifier = SVC()\n",
    "\n",
    "    # Train the SVM classifier on the reduced training data\n",
    "    svm_classifier.fit(X_train_pca, y_train)\n",
    "\n",
    "    # Step 4: Evaluate the Model\n",
    "    # Use the trained SVM classifier to predict the labels of the validation data\n",
    "    y_val_pred = svm_classifier.predict(X_val_pca)\n",
    "\n",
    "    # Evaluate the accuracy and other performance metrics of the model\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    classification_report_result = report(y_val, y_val_pred)\n",
    "\n",
    "    return accuracy, classification_report_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 5\n",
    "train_splits, val_splits = k_fold_cv_dataset_split(all_image_paths, all_labels, num_folds)\n",
    "\n",
    "fold_accuracies = []\n",
    "fold_classification_reports = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "Validation Set for Fold 1\n",
      "Accuracy: 0.68\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.71      0.70        80\n",
      "         1.0       0.66      0.64      0.65        70\n",
      "\n",
      "    accuracy                           0.68       150\n",
      "   macro avg       0.68      0.68      0.68       150\n",
      "weighted avg       0.68      0.68      0.68       150\n",
      "\n",
      "Fold: 2\n",
      "Validation Set for Fold 2\n",
      "Accuracy: 0.7181208053691275\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.87      0.76        75\n",
      "         1.0       0.81      0.57      0.67        74\n",
      "\n",
      "    accuracy                           0.72       149\n",
      "   macro avg       0.74      0.72      0.71       149\n",
      "weighted avg       0.74      0.72      0.71       149\n",
      "\n",
      "Fold: 3\n",
      "Validation Set for Fold 3\n",
      "Accuracy: 0.6241610738255033\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.74      0.66        74\n",
      "         1.0       0.67      0.51      0.58        75\n",
      "\n",
      "    accuracy                           0.62       149\n",
      "   macro avg       0.63      0.62      0.62       149\n",
      "weighted avg       0.63      0.62      0.62       149\n",
      "\n",
      "Fold: 4\n",
      "Validation Set for Fold 4\n",
      "Accuracy: 0.7315436241610739\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.88      0.79        88\n",
      "         1.0       0.74      0.52      0.62        61\n",
      "\n",
      "    accuracy                           0.73       149\n",
      "   macro avg       0.74      0.70      0.70       149\n",
      "weighted avg       0.73      0.73      0.72       149\n",
      "\n",
      "Fold: 5\n",
      "Validation Set for Fold 5\n",
      "Accuracy: 0.697986577181208\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.86      0.75        80\n",
      "         1.0       0.76      0.51      0.61        69\n",
      "\n",
      "    accuracy                           0.70       149\n",
      "   macro avg       0.72      0.68      0.68       149\n",
      "weighted avg       0.71      0.70      0.69       149\n",
      "\n"
     ]
    },
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'add' did not contain a loop with signature matching types (dtype('<U326'), dtype('<U326')) -> None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39m# Calculate and print the average accuracy and classification report across all folds\u001b[39;00m\n\u001b[0;32m     18\u001b[0m avg_accuracy \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(fold_accuracies)\n\u001b[1;32m---> 19\u001b[0m avg_classification_report \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mmean(fold_classification_reports, axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[0;32m     21\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAverage Accuracy:\u001b[39m\u001b[39m\"\u001b[39m, avg_accuracy)\n\u001b[0;32m     22\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAverage Classification Report:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, avg_classification_report)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\PC\\ML_Classification_Project\\COVID-19-CT-Classification\\env\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3464\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m   3461\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3462\u001b[0m         \u001b[39mreturn\u001b[39;00m mean(axis\u001b[39m=\u001b[39maxis, dtype\u001b[39m=\u001b[39mdtype, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m-> 3464\u001b[0m \u001b[39mreturn\u001b[39;00m _methods\u001b[39m.\u001b[39m_mean(a, axis\u001b[39m=\u001b[39maxis, dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m   3465\u001b[0m                       out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\PC\\ML_Classification_Project\\COVID-19-CT-Classification\\env\\lib\\site-packages\\numpy\\core\\_methods.py:181\u001b[0m, in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m    178\u001b[0m         dtype \u001b[39m=\u001b[39m mu\u001b[39m.\u001b[39mdtype(\u001b[39m'\u001b[39m\u001b[39mf4\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    179\u001b[0m         is_float16_result \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m ret \u001b[39m=\u001b[39m umr_sum(arr, axis, dtype, out, keepdims, where\u001b[39m=\u001b[39;49mwhere)\n\u001b[0;32m    182\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(ret, mu\u001b[39m.\u001b[39mndarray):\n\u001b[0;32m    183\u001b[0m     \u001b[39mwith\u001b[39;00m _no_nep50_warning():\n",
      "\u001b[1;31mUFuncTypeError\u001b[0m: ufunc 'add' did not contain a loop with signature matching types (dtype('<U326'), dtype('<U326')) -> None"
     ]
    }
   ],
   "source": [
    "for fold, (train_split, val_split) in enumerate(zip(train_splits, val_splits)):\n",
    "    print(\"Fold:\", fold + 1)\n",
    "\n",
    "    train_paths_fold, train_labels_fold = train_split\n",
    "    val_paths_fold, val_labels_fold = val_split\n",
    "\n",
    "    # Train and evaluate the model for the current fold\n",
    "    accuracy, classification_report_result = train_fold(train_paths_fold, train_labels_fold, val_paths_fold, val_labels_fold)\n",
    "\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_classification_reports.append(classification_report_result)\n",
    "\n",
    "    print(\"Validation Set for Fold\", fold + 1)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Classification Report:\\n\", classification_report_result)\n",
    "\n",
    "avg_accuracy = np.mean(fold_accuracies)\n",
    "print(\"Average Accuracy:\", avg_accuracy)\n",
    "\n",
    "# Print the classification report for each fold\n",
    "for i, classification_report_result in enumerate(fold_classification_reports):\n",
    "    print(\"\\nClassification Report for Fold\", i+1)\n",
    "    print(classification_report_result)\n",
    "\n",
    "# Aggregate the classification reports across all folds\n",
    "combined_classification_report = \"\\n\".join(fold_classification_reports)\n",
    "print(\"\\nCombined Classification Report:\")\n",
    "print(combined_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
