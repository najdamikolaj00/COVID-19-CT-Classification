{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from PIL import Image\n",
    "from sklearn.metrics import classification_report as report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "train_transformer = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomResizedCrop((224), scale=(0.5, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "val_transformer = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "txt_train_COVID=r'COVID\\trainCT_COVID.txt'\n",
    "txt_train_NonCOVID=r'NonCOVID\\trainCT_NonCOVID.txt'\n",
    "\n",
    "\n",
    "txt_val_COVID=r'COVID\\valCT_COVID.txt'\n",
    "txt_val_NonCOVID=r'NonCOVID\\valCT_NonCOVID.txt'\n",
    "\n",
    "\n",
    "txt_test_COVID=r'COVID\\testCT_COVID.txt'\n",
    "txt_test_NonCOVID=r'NonCOVID\\testCT_NonCOVID.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_COVID = r'C:\\Users\\PC\\ML_Classification_Project\\COVID-19-CT-Classification\\Data\\CT_COVID'\n",
    "data_NonCOVID = r'C:\\Users\\PC\\ML_Classification_Project\\COVID-19-CT-Classification\\Data\\CT_NonCOVID'\n",
    "\n",
    "with open(txt_train_COVID, 'r') as file:\n",
    "    COVID_train_paths = [os.path.join(data_COVID, line) for line in file.read().splitlines()]\n",
    "    COVID_train_labels = np.ones(len(COVID_train_paths))\n",
    "\n",
    "with open(txt_train_NonCOVID, 'r') as file:\n",
    "    NonCOVID_train_paths = [os.path.join(data_NonCOVID, line) for line in file.read().splitlines()]\n",
    "    NonCOVID_train_labels = np.zeros(len(NonCOVID_train_paths))\n",
    "\n",
    "with open(txt_val_COVID, 'r') as file:\n",
    "    COVID_val_paths = [os.path.join(data_COVID, line) for line in file.read().splitlines()]\n",
    "    COVID_val_labels = np.ones(len(COVID_val_paths))\n",
    "\n",
    "with open(txt_val_NonCOVID, 'r') as file:\n",
    "    NonCOVID_val_paths = [os.path.join(data_NonCOVID, line) for line in file.read().splitlines()]\n",
    "    NonCOVID_val_labels = np.zeros(len(NonCOVID_val_paths))\n",
    "\n",
    "with open(txt_test_COVID, 'r') as file:\n",
    "    COVID_test_paths = [os.path.join(data_COVID, line) for line in file.read().splitlines()]\n",
    "    COVID_test_labels = np.ones(len(COVID_test_paths))\n",
    "\n",
    "with open(txt_test_NonCOVID, 'r') as file:\n",
    "    NonCOVID_test_paths = [os.path.join(data_NonCOVID, line) for line in file.read().splitlines()]\n",
    "    NonCOVID_test_labels = np.zeros(len(NonCOVID_test_paths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_13508\\2796180742.py:19: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  val_images = np.array([val_transformer(Image.open(path).convert(\"RGB\")) for path in val_paths])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (118,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39m# Resize images to a consistent size\u001b[39;00m\n\u001b[0;32m     17\u001b[0m resized_train_images \u001b[39m=\u001b[39m [transforms\u001b[39m.\u001b[39mResize((\u001b[39m224\u001b[39m, \u001b[39m224\u001b[39m))(image) \u001b[39mfor\u001b[39;00m image \u001b[39min\u001b[39;00m train_images]\n\u001b[1;32m---> 19\u001b[0m val_images \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49marray([val_transformer(Image\u001b[39m.\u001b[39;49mopen(path)\u001b[39m.\u001b[39;49mconvert(\u001b[39m\"\u001b[39;49m\u001b[39mRGB\u001b[39;49m\u001b[39m\"\u001b[39;49m)) \u001b[39mfor\u001b[39;49;00m path \u001b[39min\u001b[39;49;00m val_paths])\n\u001b[0;32m     20\u001b[0m test_images \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([val_transformer(Image\u001b[39m.\u001b[39mopen(path)\u001b[39m.\u001b[39mconvert(\u001b[39m\"\u001b[39m\u001b[39mRGB\u001b[39m\u001b[39m\"\u001b[39m)) \u001b[39mfor\u001b[39;00m path \u001b[39min\u001b[39;00m test_paths])\n\u001b[0;32m     22\u001b[0m \u001b[39m# Perform PCA dimensionality reduction\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (118,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "# Load and preprocess the images\n",
    "train_paths = np.concatenate((COVID_train_paths, NonCOVID_train_paths))\n",
    "val_paths = np.concatenate((COVID_val_paths, NonCOVID_val_paths))\n",
    "test_paths = np.concatenate((COVID_test_paths, NonCOVID_test_paths))\n",
    "\n",
    "train_labels = np.concatenate((COVID_train_labels, NonCOVID_train_labels))\n",
    "val_labels = np.concatenate((COVID_val_labels, NonCOVID_val_labels))\n",
    "test_labels = np.concatenate((COVID_test_labels, NonCOVID_test_labels))\n",
    "\n",
    "train_images = []\n",
    "for path in train_paths:\n",
    "    image = Image.open(path).convert(\"RGB\")\n",
    "    image = train_transformer(image)  # Apply transformations\n",
    "    train_images.append(image)\n",
    "\n",
    "# Resize images to a consistent size\n",
    "resized_train_images = [transforms.Resize((224, 224))(image) for image in train_images]\n",
    "\n",
    "val_images = []\n",
    "for path in val_paths:\n",
    "    image = Image.open(path).convert(\"RGB\")\n",
    "    image = val_transformer(image)  # Apply transformations\n",
    "    val_images.append(image)\n",
    "\n",
    "# Resize images to a consistent size\n",
    "resized_val_images = [transforms.Resize((224, 224))(image) for image in val_images]\n",
    "\n",
    "test_images = []\n",
    "for path in test_paths:\n",
    "    image = Image.open(path).convert(\"RGB\")\n",
    "    image = val_transformer(image)  # Apply transformations\n",
    "    test_images.append(image)\n",
    "\n",
    "# Resize images to a consistent size\n",
    "resized_test_images = [transforms.Resize((224, 224))(image) for image in test_images]\n",
    "\n",
    "val_images = np.array([val_transformer(Image.open(path).convert(\"RGB\")) for path in val_paths])\n",
    "test_images = np.array([val_transformer(Image.open(path).convert(\"RGB\")) for path in test_paths])\n",
    "\n",
    "# Perform PCA dimensionality reduction\n",
    "pca = PCA(n_components=173)  # Choose the desired number of components\n",
    "train_images_pca = pca.fit_transform(resized_train_images.reshape(resized_train_images.shape[0], -1))\n",
    "val_images_pca = pca.transform(val_images.reshape(val_images.shape[0], -1))\n",
    "test_images_pca = pca.transform(test_images.reshape(test_images.shape[0], -1))\n",
    "\n",
    "# Train the SVM classifier\n",
    "svm_classifier = SVC()\n",
    "svm_classifier.fit(train_images_pca, train_labels)\n",
    "\n",
    "# Evaluate on the validation set\n",
    "val_pred = svm_classifier.predict(val_images_pca)\n",
    "val_accuracy = accuracy_score(val_labels, val_pred)\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_pred = svm_classifier.predict(test_images_pca)\n",
    "test_accuracy = accuracy_score(test_labels, test_pred)\n",
    "\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
